[{"authors":null,"categories":null,"content":"I am a fourth year Ph.D. student at the Lab for Nuclear Science and the Statistics and Data Science Center at MIT. As a Junior Investigator at the Institute for AI and Fundamental Interactions, I am mainly interested in research at the interface between machine learning and physics. Problems I work on include AI robustness, fairness, and interpretability applied to high energy physics. I am also interested in understanding deep learning foundations using tools from theoretical physics.\n","date":1659830400,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1659830400,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://okitouni.github.io/author/ouail-kitouni/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/ouail-kitouni/","section":"authors","summary":"I am a fourth year Ph.D. student at the Lab for Nuclear Science and the Statistics and Data Science Center at MIT. As a Junior Investigator at the Institute for AI and Fundamental Interactions, I am mainly interested in research at the interface between machine learning and physics.","tags":null,"title":"Ouail Kitouni","type":"authors"},{"authors":["Ziming Liu","Ouail Kitouni","Niklas Nolte","Eric Michaud","Mike Williams","Max Tegmark"],"categories":null,"content":" ","date":1659830400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1659830400,"objectID":"484c1ef3ac07d05cb724961ee4079f5f","permalink":"https://okitouni.github.io/publication/grok/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/grok/","section":"publication","summary":"We develop an effective theory to understand transformer architectures’ ability to generalize on arithmetic datasets. The theory links generalization to a particular structured representation of the embeddings and predicts a range of phenomena associated with *grokking*, or delayed generalization. Moreover, we show that grokking is one of four different phases of learning and can be avoided with proper hyper-parameter tuning. To appear in NeurIPS2022.","tags":["Deep Learning"],"title":"Towards Understanding Grokking: An Effective Theory of Representation Learning","type":"publication"},{"authors":null,"categories":null,"content":" ","date":1649768400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1649768400,"objectID":"4b90f08c3460fdd0a1cbbb9df8d0da45","permalink":"https://okitouni.github.io/talk/aps2022/","publishdate":"2022-04-12T13:00:00Z","relpermalink":"/talk/aps2022/","section":"talk","summary":" ","tags":null,"title":"Robust and Monotonic Neural Networks","type":"talk"},{"authors":["Ouail Kitouni","Niklas Nolte","Mike Williams"],"categories":null,"content":" ","date":1628294400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1628294400,"objectID":"470a94658e9e499585b83ece4193107f","permalink":"https://okitouni.github.io/publication/lipnn/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/lipnn/","section":"publication","summary":"We develop a novel architecture with an exact bound on its Lipschitz constant and which can be made monotonic in any subset of its features. This inductive bias is especially important for fairness and interpretability considerations.","tags":["Deep Learning"],"title":"Robust and Provably Monotonic Networks","type":"publication"},{"authors":["Ouail Kitouni"],"categories":null,"content":"","date":1596758400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596758400,"objectID":"44f95108a44ad2fe92adc9955d9bbdc5","permalink":"https://okitouni.github.io/random/bell/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/random/bell/","section":"random","summary":"Entanglement is one of the most fundamental aspects of quantum mechanics. It gives rise to phenomena that cannot be explained classically. In this work, we will demonstrate the non-locality of quantum mechanics through the violation of Bell’s Inequality.","tags":["Quantum Mechanics"],"title":"Bell Inequality Experiment","type":"random"},{"authors":["Ouail Kitouni","Benjamin Nachman","Constantin Weisser","Mike Williams"],"categories":null,"content":" ","date":1596758400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1596758400,"objectID":"c2bb6418b262d2480392ae6ba0d2204a","permalink":"https://okitouni.github.io/publication/mode/","publishdate":"2017-01-01T00:00:00Z","relpermalink":"/publication/mode/","section":"publication","summary":"Moment Decorrelation (MoDe) is a tool that can enforce decorrelation between some nuisance parameter (or protected attribute in ML fairness lingo) and the response of some model with gradient-based optimization (a neural network for example.) It can force trained models to have the same response across different values of the protected attribute but it can also go beyond simple decorrelation. For example, MoDe can constrain the response function to be linear or quadratic in the protected attribute.","tags":["Deep Learning"],"title":"Controlling Classifier Bias with Moment Decomposition: A Method to Enhance Searches for Resonances","type":"publication"},{"authors":["Ouail Kitouni"],"categories":[],"content":"from IPython.core.display import Image Image('https://www.python.org/static/community_logos/python-logo-master-v3-TM-flattened.png') print(\u0026quot;Welcome to Academic!\u0026quot;) Welcome to Academic! Install Python and JupyterLab Install Anaconda which includes Python 3 and JupyterLab.\nAlternatively, install JupyterLab with pip3 install jupyterlab.\nCreate or upload a Jupyter notebook Run the following commands in your Terminal, substituting \u0026lt;MY-WEBSITE-FOLDER\u0026gt; and \u0026lt;SHORT-POST-TITLE\u0026gt; with the file path to your Academic website folder and a short title for your blog post (use hyphens instead of spaces), respectively:\nmkdir -p \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ cd \u0026lt;MY-WEBSITE-FOLDER\u0026gt;/content/post/\u0026lt;SHORT-POST-TITLE\u0026gt;/ jupyter lab index.ipynb The jupyter command above will launch the JupyterLab editor, allowing us to add Academic metadata and write the content.\nEdit your post metadata The first cell of your Jupter notebook will contain your post metadata (front matter).\nIn Jupter, choose Markdown as the type of the first cell and wrap your Academic metadata in three dashes, indicating that it is YAML front matter:\n--- title: My post's title date: 2019-09-01 # Put any other Academic metadata here... --- Edit the metadata of your post, using the documentation as a guide to the available options.\nTo set a featured image, place an image named featured into your post\u0026rsquo;s folder.\nFor other tips, such as using math, see the guide on writing content with Academic.\nConvert notebook to Markdown jupyter nbconvert index.ipynb --to markdown --NbConvertApp.output_files_dir=. Example This post was created with Jupyter. The orginal files can be found at https://github.com/gcushen/hugo-academic/tree/master/exampleSite/content/post/jupyter\n","date":1549324800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1567641600,"objectID":"c55acc8b759e9962841e40246aca1fc1","permalink":"https://okitouni.github.io/post/grokking-thoughts/","publishdate":"2019-02-05T00:00:00Z","relpermalink":"/post/grokking-thoughts/","section":"post","summary":"Learn how to blog in Academic using Jupyter notebooks","tags":[],"title":"Some thoughts on Grokking","type":"post"}]