<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Ouail Kitouni</title><link>https://okitouni.github.io/author/ouail-kitouni/</link><atom:link href="https://okitouni.github.io/author/ouail-kitouni/index.xml" rel="self" type="application/rss+xml"/><description>Ouail Kitouni</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Thu, 01 Jun 2023 00:00:00 +0000</lastBuildDate><image><url>https://okitouni.github.io/images/icon_hu78093045f097574c5772539a9c4bdc89_10083_512x512_fill_lanczos_center_3.png</url><title>Ouail Kitouni</title><link>https://okitouni.github.io/author/ouail-kitouni/</link></image><item><title>NuCLR: Nuclear Co-Learned Representations</title><link>https://okitouni.github.io/publication/nuclr/</link><pubDate>Thu, 01 Jun 2023 00:00:00 +0000</pubDate><guid>https://okitouni.github.io/publication/nuclr/</guid><description>&lt;!--
&lt;div class="alert alert-note">
&lt;div>
Click the &lt;em>Slides&lt;/em> button above to demo Academic&amp;rsquo;s Markdown slides feature.
&lt;/div>
&lt;/div>
Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/).
--></description></item><item><title>Random Animations and Visualizations</title><link>https://okitouni.github.io/post/animations/</link><pubDate>Fri, 18 Nov 2022 00:00:00 +0000</pubDate><guid>https://okitouni.github.io/post/animations/</guid><description>&lt;!-- Change this color later -->
&lt;p>[This page is a work-in-progress.]&lt;/p>
&lt;h2 id="neural-estimation-energy-movers-distance-neemo">Neural Estimation Energy Mover&amp;rsquo;s Distance (NEEMo)&lt;/h2>
&lt;h3 id="triangle-and-ellipse-fit">Triangle and Ellipse Fit&lt;/h3>
&lt;p>Fitting the target distribution (green) with an ellipse and a triangle (red) using the NEEMo algorithm.&lt;/p>
&lt;video controls >
&lt;source src="triangleFitx5.mp4" type="video/mp4">
&lt;/video>
&lt;h3 id="multi-circle-fit">Multi-circle Fit&lt;/h3>
&lt;p>Now we fit the target distribution (green) with three circles (red).
&lt;video controls >
&lt;source src="CircleFitx10.mp4" type="video/mp4">
&lt;/video>&lt;/p></description></item><item><title>NEEMo: Geometric Fitting using Neural Estimation of the Energy Mover's Distance</title><link>https://okitouni.github.io/publication/neemo/</link><pubDate>Wed, 21 Sep 2022 00:00:00 +0000</pubDate><guid>https://okitouni.github.io/publication/neemo/</guid><description>&lt;!--
&lt;div class="alert alert-note">
&lt;div>
Click the &lt;em>Slides&lt;/em> button above to demo Academic&amp;rsquo;s Markdown slides feature.
&lt;/div>
&lt;/div>
Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/).
--></description></item><item><title>Some thoughts on Grokking</title><link>https://okitouni.github.io/post/grokking-thoughts/</link><pubDate>Wed, 21 Sep 2022 00:00:00 +0000</pubDate><guid>https://okitouni.github.io/post/grokking-thoughts/</guid><description>&lt;!-- Change this color later -->
&lt;p>[This page is a work-in-progress.]&lt;/p>
&lt;p>Grokking, the phenomenon by which some models generalize well after overfitting, was very intriguing when it was first observed. In this post, I will try to summarize some observations I made while trying to understand this phenomenon.&lt;/p>
&lt;h2 id="formation-of-structure-animated">Formation of structure (animated)&lt;/h2>
&lt;p>The example below is an animation of the first Figure from &lt;a href="https://okitouni.github.io/publication/grok/">our Grokking paper&lt;/a>.
We visualize the first two principal components of the embeddings of a transformer model trained on the task of addition modulo 59. An interesting feature is that generalization seems to coincide with learnning an ordered representation of the embeddings around a circle (much like how a human would reason about modular addition).
&lt;video controls >
&lt;source src="modular-addition59-deep_pca12.mp4" type="video/mp4">
&lt;/video>
What is more intriguing is that this &amp;ldquo;perfect&amp;rdquo; representation actually exists very early (up to local ordering of embeddings). In the animation below, the axes are fixed to the first two principal components &lt;strong>at the end of training&lt;/strong>. This seems to suggest that the network picks a good representation at initialization and prunes away the noise throughout training. As one might expect, this &amp;ldquo;lottery ticket&amp;rdquo; found at initialization gets better (&lt;em>i.e.&lt;/em>, closer to the perfect representation) the wider the model dimension.
&lt;video controls >
&lt;source src="modular-addition59-deep_pca12_fixed.mp4" type="video/mp4">
&lt;/video>
&lt;em>N.b.&lt;/em>, it is not necessary to get a perfect ordering in the first two principal components for generalization to occur. In some cases, the circle can be &amp;ldquo;spread out&amp;rdquo; over many components at different frequencies. For instance, the circle can be ordered modulo 2 in the first two principal components such that there are two degenerate cicles on top of each other. But this multiplicity is broken in lower principal components.&lt;/p>
&lt;h2 id="simple-grokking">Simple Grokking&lt;/h2>
&lt;p>If you&amp;rsquo;re intrested in playing around with Grokking, I made a very simple implementation that shows a clear delay in generalization. The task is modular addition. The model is a simple 2-layer MLP that takes in two learnable embeddings of dimension hidden_dim=128 concatenated together. Each embedding representes an integer and the target is their sum modulo 53.
The code can be found here: &lt;a href="https://github.com/okitouni/simple-grokking" target="_blank" rel="noopener">https://github.com/okitouni/simple-grokking&lt;/a>
&lt;img src="metrics_grokking.jpg" alt="metrics_grokking">
To undo Grokking (i.e. generalize earlier) we can simply increase the amount of weight decay used (from 0.03 to 5) and get the following results:
&lt;img src="metrics_comprehension.jpg" alt="metrics_comprehension">&lt;/p></description></item><item><title>Towards Understanding Grokking: An Effective Theory of Representation Learning</title><link>https://okitouni.github.io/publication/grok/</link><pubDate>Sun, 07 Aug 2022 00:00:00 +0000</pubDate><guid>https://okitouni.github.io/publication/grok/</guid><description>&lt;!--
&lt;div class="alert alert-note">
&lt;div>
Click the &lt;em>Slides&lt;/em> button above to demo Academic&amp;rsquo;s Markdown slides feature.
&lt;/div>
&lt;/div>
Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/).
--></description></item><item><title>Robust and Provably Monotonic Networks</title><link>https://okitouni.github.io/publication/lipnn/</link><pubDate>Sat, 07 Aug 2021 00:00:00 +0000</pubDate><guid>https://okitouni.github.io/publication/lipnn/</guid><description>&lt;!--
&lt;div class="alert alert-note">
&lt;div>
Click the &lt;em>Slides&lt;/em> button above to demo Academic&amp;rsquo;s Markdown slides feature.
&lt;/div>
&lt;/div>
Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/).
--></description></item><item><title>Bell Inequality Experiment</title><link>https://okitouni.github.io/random/bell/</link><pubDate>Fri, 07 Aug 2020 00:00:00 +0000</pubDate><guid>https://okitouni.github.io/random/bell/</guid><description/></item><item><title>Controlling Classifier Bias with Moment Decomposition: A Method to Enhance Searches for Resonances</title><link>https://okitouni.github.io/publication/mode/</link><pubDate>Fri, 07 Aug 2020 00:00:00 +0000</pubDate><guid>https://okitouni.github.io/publication/mode/</guid><description>&lt;!--
&lt;div class="alert alert-note">
&lt;div>
Click the &lt;em>Slides&lt;/em> button above to demo Academic&amp;rsquo;s Markdown slides feature.
&lt;/div>
&lt;/div>
Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/).
--></description></item></channel></rss>