<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Ouail Kitouni</title><link>https://okitouni.github.io/</link><atom:link href="https://okitouni.github.io/index.xml" rel="self" type="application/rss+xml"/><description>Ouail Kitouni</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 21 Jun 2023 00:00:00 +0000</lastBuildDate><image><url>https://okitouni.github.io/images/icon_hu78093045f097574c5772539a9c4bdc89_10083_512x512_fill_lanczos_center_3.png</url><title>Ouail Kitouni</title><link>https://okitouni.github.io/</link></image><item><title>The Physics of Deep Learning</title><link>https://okitouni.github.io/post/physics-of-dl/</link><pubDate>Wed, 21 Jun 2023 00:00:00 +0000</pubDate><guid>https://okitouni.github.io/post/physics-of-dl/</guid><description>&lt;!-- Change this color later -->
&lt;!-- I don't want to write a long-winded introduction on how the study of the steam engine which started as an engineering discipline flourished into a theory of thermodynamics. Or how physics specializes in breaking down complex systems (just like neural networks) into their simplest components to derive theories that explain the emergent behavior of the system. I will just assume that you are already convinced that physics is a good place to look for inspiration.
With that said, this is will hopefully be a series of short blog posts that summarize some key ideas and concepts in our understanding of how deep learning works. I obviously will not claim that the material presented here will actually be *THE* physics approach to deep learning. In particular because many people will have many definitions for what that might be. So I will clarify the definition I will employ here. To me, a physics approach to deep learning is one that is inspired by the way physicists think about problems. This is not to say that the approach will be rigorous or even correct. All we aim to achieve here is an intuitive understanding of some key components of deep learning. This intuition should be able to generalize across different settings to a certain extent and further, it should be able to make some testable predictions. This approach is very pragmatic by its nature, but I plan on putting in additional effort to make sure *anyone* can follow along. For practitioner, this would translate to adding a new tool to guide intuition and for theorists, this would translate to a new way of thinking about the problem, and to everyone else, I hope you gain a new appreciation for common or foreign concepts in deep learning.
Some topics I plan on talking about:
- Grokking, or generalization beyond overfitting.
- Lottery Ticket Hypothesis.
- Scaling Laws and infinite width limits.
- Topics in Mechanistic Interpretability.
- Miscellaneous topics in optimization via gradient descent in the Deep Learning setting. This includes things like the role of normalization, adaptive optimization, implicit/explicit regularization, etc. -->
&lt;p>I don&amp;rsquo;t want to write a long-winded introduction on how the study of the steam engine, which started as an engineering discipline, flourished into a theory of thermodynamics. Or how physics specializes in breaking down complex systems into their simplest components to derive theories that explain the emergent behavior of the system. I assume you are already convinced that physics is a good place to seek inspiration.&lt;/p>
&lt;p>This will be a series of short blog posts summarizing a sample of ideas and concepts in our understanding of deep learning. I will not claim that the material presented here will be &lt;em>THE&lt;/em> physics approach to deep learning, as that could mean many things to different people. My definition of a physics approach to deep learning is one that adopts physicist-style thinking. This is not to say that the approach will be rigorous or even &lt;em>entirely&lt;/em> correct. All we aim to achieve here is an intuitive understanding of some key components of deep learning. This intuition should generalize across different settings to a certain extent and make predictions we can test empirically. This approach is very pragmatic by its nature, and I plan on expending additional effort to ensure &lt;em>anyone&lt;/em> can follow along. For those in the trenches, this would translate to adding a new tool to guide intuition in designing, training, and deploying models, and to everyone else, I hope you gain a fresh perspective and a new appreciation for familiar (or foreign) concepts in deep learning.&lt;/p>
&lt;p>Some topics I plan on talking about:&lt;/p>
&lt;ul>
&lt;li>Grokking, or generalization beyond overfitting.&lt;/li>
&lt;li>Lottery Ticket Hypothesis.&lt;/li>
&lt;li>Scaling Laws and infinite width limits.&lt;/li>
&lt;li>Topics in Mechanistic Interpretability.&lt;/li>
&lt;li>Miscellaneous topics in optimization via gradient descent in the Deep Learning setting. This includes topics like the role of normalization, adaptive optimization, implicit/explicit regularization, etc.&lt;/li>
&lt;/ul></description></item><item><title>NuCLR: Nuclear Co-Learned Representations</title><link>https://okitouni.github.io/publication/nuclr/</link><pubDate>Thu, 01 Jun 2023 00:00:00 +0000</pubDate><guid>https://okitouni.github.io/publication/nuclr/</guid><description>&lt;!--
&lt;div class="alert alert-note">
&lt;div>
Click the &lt;em>Slides&lt;/em> button above to demo Academic&amp;rsquo;s Markdown slides feature.
&lt;/div>
&lt;/div>
Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/).
--></description></item><item><title>Random Animations and Visualizations</title><link>https://okitouni.github.io/post/animations/</link><pubDate>Fri, 18 Nov 2022 00:00:00 +0000</pubDate><guid>https://okitouni.github.io/post/animations/</guid><description>&lt;!-- Change this color later -->
&lt;p>[This page is a work-in-progress.]&lt;/p>
&lt;h2 id="neural-estimation-energy-movers-distance-neemo">Neural Estimation Energy Mover&amp;rsquo;s Distance (NEEMo)&lt;/h2>
&lt;h3 id="triangle-and-ellipse-fit">Triangle and Ellipse Fit&lt;/h3>
&lt;p>Fitting the target distribution (green) with an ellipse and a triangle (red) using the NEEMo algorithm.&lt;/p>
&lt;video controls >
&lt;source src="triangleFitx5.mp4" type="video/mp4">
&lt;/video>
&lt;h3 id="multi-circle-fit">Multi-circle Fit&lt;/h3>
&lt;p>Now we fit the target distribution (green) with three circles (red).
&lt;video controls >
&lt;source src="CircleFitx10.mp4" type="video/mp4">
&lt;/video>&lt;/p></description></item><item><title>NEEMo: Geometric Fitting using Neural Estimation of the Energy Mover's Distance</title><link>https://okitouni.github.io/publication/neemo/</link><pubDate>Wed, 21 Sep 2022 00:00:00 +0000</pubDate><guid>https://okitouni.github.io/publication/neemo/</guid><description>&lt;!--
&lt;div class="alert alert-note">
&lt;div>
Click the &lt;em>Slides&lt;/em> button above to demo Academic&amp;rsquo;s Markdown slides feature.
&lt;/div>
&lt;/div>
Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/).
--></description></item><item><title>Some thoughts on Grokking</title><link>https://okitouni.github.io/post/grokking-thoughts/</link><pubDate>Wed, 21 Sep 2022 00:00:00 +0000</pubDate><guid>https://okitouni.github.io/post/grokking-thoughts/</guid><description>&lt;!-- Change this color later -->
&lt;p>[This page is a work-in-progress.]&lt;/p>
&lt;p>Grokking, the phenomenon by which some models generalize well after overfitting, was very intriguing when it was first observed. In this post, I will try to summarize some observations I made while trying to understand this phenomenon.&lt;/p>
&lt;h2 id="formation-of-structure-animated">Formation of structure (animated)&lt;/h2>
&lt;p>The example below is an animation of the first Figure from &lt;a href="https://okitouni.github.io/publication/grok/">our Grokking paper&lt;/a>.
We visualize the first two principal components of the embeddings of a transformer model trained on the task of addition modulo 59. An interesting feature is that generalization seems to coincide with learnning an ordered representation of the embeddings around a circle (much like how a human would reason about modular addition).
&lt;video controls >
&lt;source src="modular-addition59-deep_pca12.mp4" type="video/mp4">
&lt;/video>
What is more intriguing is that this &amp;ldquo;perfect&amp;rdquo; representation actually exists very early (up to local ordering of embeddings). In the animation below, the axes are fixed to the first two principal components &lt;strong>at the end of training&lt;/strong>. This seems to suggest that the network picks a good representation at initialization and prunes away the noise throughout training. As one might expect, this &amp;ldquo;lottery ticket&amp;rdquo; found at initialization gets better (&lt;em>i.e.&lt;/em>, closer to the perfect representation) the wider the model dimension.
&lt;video controls >
&lt;source src="modular-addition59-deep_pca12_fixed.mp4" type="video/mp4">
&lt;/video>
&lt;em>N.b.&lt;/em>, it is not necessary to get a perfect ordering in the first two principal components for generalization to occur. In some cases, the circle can be &amp;ldquo;spread out&amp;rdquo; over many components at different frequencies. For instance, the circle can be ordered modulo 2 in the first two principal components such that there are two degenerate cicles on top of each other. But this multiplicity is broken in lower principal components.&lt;/p>
&lt;h2 id="simple-grokking">Simple Grokking&lt;/h2>
&lt;p>If you&amp;rsquo;re intrested in playing around with Grokking, I made a very simple implementation that shows a clear delay in generalization. The task is modular addition. The model is a simple 2-layer MLP that takes in two learnable embeddings of dimension hidden_dim=128 concatenated together. Each embedding representes an integer and the target is their sum modulo 53.
The code can be found here: &lt;a href="https://github.com/okitouni/simple-grokking" target="_blank" rel="noopener">https://github.com/okitouni/simple-grokking&lt;/a>
&lt;img src="metrics_grokking.jpg" alt="metrics_grokking">
To undo Grokking (i.e. generalize earlier) we can simply increase the amount of weight decay used (from 0.03 to 5) and get the following results:
&lt;img src="metrics_comprehension.jpg" alt="metrics_comprehension">&lt;/p></description></item><item><title>Towards Understanding Grokking: An Effective Theory of Representation Learning</title><link>https://okitouni.github.io/publication/grok/</link><pubDate>Sun, 07 Aug 2022 00:00:00 +0000</pubDate><guid>https://okitouni.github.io/publication/grok/</guid><description>&lt;!--
&lt;div class="alert alert-note">
&lt;div>
Click the &lt;em>Slides&lt;/em> button above to demo Academic&amp;rsquo;s Markdown slides feature.
&lt;/div>
&lt;/div>
Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/).
--></description></item><item><title>Robust and Monotonic Neural Networks</title><link>https://okitouni.github.io/talk/aps2022/</link><pubDate>Tue, 12 Apr 2022 13:00:00 +0000</pubDate><guid>https://okitouni.github.io/talk/aps2022/</guid><description>&lt;!--
&lt;div class="alert alert-note">
&lt;div>
Click on the &lt;strong>Slides&lt;/strong> button above to view the built-in slides feature.
&lt;/div>
&lt;/div>
Slides can be added in a few ways:
- **Create** slides using Academic's [*Slides*](https://sourcethemes.com/academic/docs/managing-content/#create-slides) feature and link using `slides` parameter in the front matter of the talk file
- **Upload** an existing slide deck to `static/` and link using `url_slides` parameter in the front matter of the talk file
- **Embed** your slides (e.g. Google Slides) or presentation video on this page using [shortcodes](https://sourcethemes.com/academic/docs/writing-markdown-latex/).
Further talk details can easily be added to this page using *Markdown* and $\rm \LaTeX$ math code. --></description></item><item><title>Robust and Provably Monotonic Networks</title><link>https://okitouni.github.io/publication/lipnn/</link><pubDate>Sat, 07 Aug 2021 00:00:00 +0000</pubDate><guid>https://okitouni.github.io/publication/lipnn/</guid><description>&lt;!--
&lt;div class="alert alert-note">
&lt;div>
Click the &lt;em>Slides&lt;/em> button above to demo Academic&amp;rsquo;s Markdown slides feature.
&lt;/div>
&lt;/div>
Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/).
--></description></item><item><title>Bell Inequality Experiment</title><link>https://okitouni.github.io/random/bell/</link><pubDate>Fri, 07 Aug 2020 00:00:00 +0000</pubDate><guid>https://okitouni.github.io/random/bell/</guid><description/></item><item><title>Controlling Classifier Bias with Moment Decomposition: A Method to Enhance Searches for Resonances</title><link>https://okitouni.github.io/publication/mode/</link><pubDate>Fri, 07 Aug 2020 00:00:00 +0000</pubDate><guid>https://okitouni.github.io/publication/mode/</guid><description>&lt;!--
&lt;div class="alert alert-note">
&lt;div>
Click the &lt;em>Slides&lt;/em> button above to demo Academic&amp;rsquo;s Markdown slides feature.
&lt;/div>
&lt;/div>
Supplementary notes can be added here, including [code and math](https://sourcethemes.com/academic/docs/writing-markdown-latex/).
--></description></item></channel></rss>